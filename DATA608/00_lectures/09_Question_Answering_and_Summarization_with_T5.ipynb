{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kl6fW8Fkf3vN"
      },
      "source": [
        "# Question Answering and Summarization with [T5](https://arxiv.org/pdf/1910.10683.pdf)\n",
        "\n",
        "\n",
        "Google's T5 is a Sequence to Sequence model that was trained on over 15 different NLP datasets with various problem types, raning from Text Summarization, Question Answering, Translation to various semantical deduction tasks, which enriches T5's ability to map token sequences to semantic vectors which contain more meaning, which T5 leverages to generalize across various tasks and even to never before trained tasks.\n",
        "\n",
        "On top of this, T5 is trained on the standard Word prediction task, which most transformer based models like BERT, GPT, ELMO have been trained on. This gives T5 general knowledge of real world concepts to additionally enhance its understanding.\n",
        "\n",
        "With T5 you can answer **general knowledge based questions given no context** and in addition answer **questions on text databases**.      \n",
        "These questions can be asked in natural human.\n",
        "\n",
        "\n",
        "## What is a `open book question`? \n",
        "You can imagine an `open book` question similar to an examen where you are allowed to bring in text documents or cheat sheets that help you answer questions in an examen. Kinda like bringing a history book to an history examen. \n",
        "\n",
        "In `T5's` terms, this means the model is given a `question` and an **additional piece of textual information** or so called `context`.\n",
        "\n",
        "This enables the `T5` model to answer questions on textual datasets like `medical records`,`newsarticles` , `wiki-databases` , `stories` and `movie scripts` , `product descriptions`, 'legal documents' and many more.\n",
        "\n",
        "\n",
        "\n",
        "## What is a `closed book question`? \n",
        "A `closed book question` is the exact opposite of a `open book question`. In an examen scenario, you are only allowed to use what you have memorized in your brain and nothing else.      \n",
        "In `T5's` terms this means that T5 can only use it's stored weights to answer a `question` and is given **no aditional context**.        \n",
        "`T5` was pre-trained on the [C4 dataset](https://commoncrawl.org/) which contains **petabytes  of web crawling data**  collected over the last 8 years, including Wikipedia in every language.\n",
        "\n",
        "\n",
        "This gives `T5` the broad knowledge of the internet stored in it's weights to answer various `closed book questions` \n",
        "\n",
        "\n",
        "\n",
        "<!-- [T5]() -->\n",
        "![T5 GIF](https://1.bp.blogspot.com/-o4oiOExxq1s/Xk26XPC3haI/AAAAAAAAFU8/NBlvOWB84L0PTYy9TzZBaLf6fwPGJTR0QCLcBGAsYHQ/s1600/image3.gif)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><h4><b>MODEL LIST</b></h4>\n",
        "\n",
        "Below is a list of Text Generation models. You can get detailed information about the models by clicking on the links.\n",
        "\n",
        "|index|model|lang|\n",
        "|-----:|:-----|----|\n",
        "| 1| [t5_active_to_passive_styletransfer](https://nlp.johnsnowlabs.com/2022/05/31/t5_active_to_passive_styletransfer_en_3_0.html)  |en|\n",
        "| 2| [t5_base](https://nlp.johnsnowlabs.com/2022/05/31/t5_base_en_3_0.html)  |en|\n",
        "| 3| [t5_base_mediqa_mnli](https://nlp.johnsnowlabs.com/2021/02/19/t5_base_mediqa_mnli_en.html)  |en|\n",
        "| 4| [t5_formal_to_informal_styletransfer](https://nlp.johnsnowlabs.com/2022/05/31/t5_formal_to_informal_styletransfer_en_3_0.html)  |en|\n",
        "| 5| [t5_grammar_error_corrector](https://nlp.johnsnowlabs.com/2022/01/12/t5_grammar_error_corrector_en.html)  |en|\n",
        "| 6| [t5_informal_to_formal_styletransfer](https://nlp.johnsnowlabs.com/2022/05/31/t5_informal_to_formal_styletransfer_en_3_0.html)  |en|\n",
        "| 7| [t5_passive_to_active_styletransfer](https://nlp.johnsnowlabs.com/2022/05/31/t5_passive_to_active_styletransfer_en_3_0.html)  |en|\n",
        "| 8| [t5_question_generation_small](https://nlp.johnsnowlabs.com/2022/07/05/t5_question_generation_small_en_3_0.html)  |en|\n",
        "| 9| [t5_small](https://nlp.johnsnowlabs.com/2022/05/31/t5_small_en_3_0.html)  |en|\n",
        "| 10| [t5_small_wikiSQL](https://nlp.johnsnowlabs.com/2022/05/31/t5_small_wikiSQL_en_3_0.html)  |en|\n",
        "| 11| [t5_grammar_error_corrector](https://nlp.johnsnowlabs.com/2022/11/28/t5_grammar_error_corrector_en.html)  |en|\n",
        "\n",
        "</center>"
      ],
      "metadata": {
        "id": "CbOzz-Ve7jV-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06DMedvcgjKa"
      },
      "source": [
        "## Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Mc2rld9f7YW"
      },
      "source": [
        "!pip install -q pyspark==3.3.0 spark-nlp==4.2.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "KjcBNzFVgoky",
        "outputId": "ed2e1ded-c269-4437-afdc-588021de9535"
      },
      "source": [
        "import sparknlp\n",
        "\n",
        "spark = sparknlp.start()\n",
        "\n",
        "from sparknlp.base import *\n",
        "from sparknlp.common import *\n",
        "from sparknlp.annotator import *\n",
        "from pyspark.ml import Pipeline\n",
        "import pandas as pd\n",
        "\n",
        "print(\"Spark NLP version\", sparknlp.version())\n",
        "print(\"Apache Spark version:\", spark.version)\n",
        "\n",
        "spark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version 4.2.4\n",
            "Apache Spark version: 3.3.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fe90f1db610>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://0906b37168c6:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.3.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZyycKyzQcwQ"
      },
      "source": [
        "# Download T5 Model and Create Spark NLP Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXdynTiFHKLK",
        "outputId": "26be4438-5862-47dd-8bef-8dcd3ef0dc05"
      },
      "source": [
        "documentAssembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"text\") \\\n",
        "    .setOutputCol(\"document\") \n",
        "\n",
        "# Can take in document or sentence columns\n",
        "t5 = T5Transformer.pretrained(name='t5_base',lang='en')\\\n",
        "    .setInputCols('document')\\\n",
        "    .setOutputCol(\"T5\")\\\n",
        "    .setMaxOutputLength(400)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t5_base download started this may take some time.\n",
            "Approximate size to download 451.8 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzSthAbHS72B"
      },
      "source": [
        "# Answering Questions "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aem2oG-iQhAA"
      },
      "source": [
        "## Set the Task to `question`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAmbHcTjM6BP",
        "outputId": "545b847c-3f0e-4454-c565-d85a62805908"
      },
      "source": [
        "# Set the task for questions on T5. Depending to what this is currently set, we get different behaivour\n",
        "t5.setTask('question')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5TRANSFORMER_8078c2d39352"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "airN5MRMQq7h"
      },
      "source": [
        "## Answer **Closed Book Questions**  \n",
        "Closed book means that no additional context is given and the model must answer the question with the knowledge stored in it's weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFVGcgXrHSfZ",
        "outputId": "eb75afa3-740a-4ee0-b335-8e1fa45438e3"
      },
      "source": [
        "# Build pipeline with T5\n",
        "pipe_components = [documentAssembler,t5]\n",
        "pipeline = Pipeline().setStages( pipe_components)\n",
        "\n",
        "# define Data\n",
        "data = [[\"Who is president of Nigeria? \"],\n",
        "        [\"What is the most common language in India? \"],\n",
        "        [\"What is the capital of Germany? \"],]\n",
        "df=spark.createDataFrame(data).toDF('text')\n",
        "\n",
        "#Predict on text data with T5\n",
        "model = pipeline.fit(df)\n",
        "annotated_df = model.transform(df)\n",
        "annotated_df.select(['text','t5.result']).show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------+------------------+\n",
            "|text                                       |result            |\n",
            "+-------------------------------------------+------------------+\n",
            "|Who is president of Nigeria?               |[Muhammadu Buhari]|\n",
            "|What is the most common language in India? |[Hindi]           |\n",
            "|What is the capital of Germany?            |[Berlin]          |\n",
            "+-------------------------------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f86fFTXMQvPt"
      },
      "source": [
        "## Answer **Open Book Questions** \n",
        "These are questions where we give the model some additional context, that is used to answer the question"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9isRW-2lFsfl",
        "outputId": "99e37c0a-048b-498f-bee1-8bf600ee0ddf"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "context    = 'context: Peters last week was terrible! He had an accident and broke his leg while skiing!'\n",
        "question1  = 'question: Why was peters week so bad? ' #\n",
        "question2  = 'question: How did peter broke his leg? ' \n",
        "question3  = 'question: How did peter broke his leg? '\n",
        " \n",
        "data = [[question1+context],[question2+context],[question3+context],]\n",
        "df=spark.createDataFrame(data).toDF('text')\n",
        "\n",
        "#Predict on text data with T5\n",
        "model = pipeline.fit(df)\n",
        "annotated_df = model.transform(df)\n",
        "annotated_df.select(['text','t5.result']).show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------+\n",
            "|text                                                                                                                             |result                                             |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------+\n",
            "|question: Why was peters week so bad? context: Peters last week was terrible! He had an accident and broke his leg while skiing! |[He had an accident and broke his leg while skiing]|\n",
            "|question: How did peter broke his leg? context: Peters last week was terrible! He had an accident and broke his leg while skiing!|[skiing]                                           |\n",
            "|question: How did peter broke his leg? context: Peters last week was terrible! He had an accident and broke his leg while skiing!|[skiing]                                           |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWpiawiA5GwS",
        "outputId": "c14addf7-a8cc-40c5-b0d4-5337e019e5b6"
      },
      "source": [
        "# Ask T5 questions in the context of a News Article\n",
        "question1 = 'question: Who is Jack ma? '\n",
        "question2 = 'question: Who is founder of Alibaba Group? '\n",
        "question3 = 'question: When did Jack Ma re-appear? '\n",
        "question4 = 'question: How did Alibaba stocks react? '\n",
        "question5 = 'question: Whom did Jack Ma meet? '\n",
        "question6 = 'question: Who did Jack Ma hide from? '\n",
        "\n",
        "\n",
        "# from https://www.bbc.com/news/business-55728338 \n",
        "news_article_context = \"\"\" context:\n",
        "Alibaba Group founder Jack Ma has made his first appearance since Chinese regulators cracked down on his business empire.\n",
        "His absence had fuelled speculation over his whereabouts amid increasing official scrutiny of his businesses.\n",
        "The billionaire met 100 rural teachers in China via a video meeting on Wednesday, according to local government media.\n",
        "Alibaba shares surged 5% on Hong Kong's stock exchange on the news.\n",
        "\"\"\"\n",
        "\n",
        "data = [\n",
        "             [question1+ news_article_context],\n",
        "             [question2+ news_article_context],\n",
        "             [question3+ news_article_context],\n",
        "             [question4+ news_article_context],\n",
        "             [question5+ news_article_context],\n",
        "             [question6+ news_article_context]]\n",
        "\n",
        "\n",
        "df=spark.createDataFrame(data).toDF('text')\n",
        "\n",
        "#Predict on text data with T5\n",
        "model = pipeline.fit(df)\n",
        "annotated_df = model.transform(df)\n",
        "annotated_df.select(['t5.result']).show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------+\n",
            "|result                 |\n",
            "+-----------------------+\n",
            "|[Alibaba Group founder]|\n",
            "|[Jack Ma]              |\n",
            "|[Wednesday]            |\n",
            "|[surged 5%]            |\n",
            "|[100 rural teachers]   |\n",
            "|[Chinese regulators]   |\n",
            "+-----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUfqQBdtNTS6"
      },
      "source": [
        "# Summarize documents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1-x-TLL5iJK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5409d11-8ee2-4f94-d78b-697a53fa584f"
      },
      "source": [
        "# Set the task for questions on T5\n",
        "t5.setTask('summarize')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5TRANSFORMER_8078c2d39352"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzKvMHteNUTB",
        "outputId": "f5a3227d-c481-461d-c032-f1ceb9d1571c"
      },
      "source": [
        "# https://www.reuters.com/article/instant-article/idCAKBN2AA2WF\n",
        "\n",
        "text = \"\"\"(Reuters) - Mastercard Inc said on Wednesday it was planning to offer support for some cryptocurrencies on its network this year, joining a string of big-ticket firms that have pledged similar support.\n",
        "\n",
        "The credit-card giant’s announcement comes days after Elon Musk’s Tesla Inc revealed it had purchased $1.5 billion of bitcoin and would soon accept it as a form of payment.\n",
        "\n",
        "Asset manager BlackRock Inc and payments companies Square and PayPal have also recently backed cryptocurrencies.\n",
        "\n",
        "Mastercard already offers customers cards that allow people to transact using their cryptocurrencies, although without going through its network.\n",
        "\n",
        "\"Doing this work will create a lot more possibilities for shoppers and merchants, allowing them to transact in an entirely new form of payment. This change may open merchants up to new customers who are already flocking to digital assets,\" Mastercard said. (mstr.cd/3tLaPZM)\n",
        "\n",
        "Mastercard specified that not all cryptocurrencies will be supported on its network, adding that many of the hundreds of digital assets in circulation still need to tighten their compliance measures.\n",
        "\n",
        "Many cryptocurrencies have struggled to win the trust of mainstream investors and the general public due to their speculative nature and potential for money laundering.\n",
        "\"\"\"\n",
        "data = [[text]]\n",
        "df=spark.createDataFrame(data).toDF('text')\n",
        "#Predict on text data with T5\n",
        "model = pipeline.fit(df)\n",
        "annotated_df = model.transform(df)\n",
        "annotated_df.select(['t5.result']).show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|result                                                                                                                                                                                                                                                                                                                                                            |\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|[mastercard said on Wednesday it was planning to offer support for some cryptocurrencies on its network this year . the credit-card giant’s announcement comes days after Elon Musk’s Tesla Inc revealed it had purchased $1.5 billion of bitcoin . asset manager blackrock and payments companies Square and PayPal have also recently backed cryptocurrencies .]|\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdII1LrdNq3p",
        "outputId": "5bc00a17-7de1-49e3-d2ca-03ec07d89b73"
      },
      "source": [
        "v = annotated_df.take(1)\n",
        "print(f\"Original Length {len(v[0].text)}   Summarized Length : {len(v[0].T5[0].result)} \")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Length 1284   Summarized Length : 352 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "do_7s8baOCej",
        "outputId": "7425b0b5-b6b5-45b3-a07c-3db2c2fd35c4"
      },
      "source": [
        "# Full summarized text\n",
        "v[0].T5[0].result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mastercard said on Wednesday it was planning to offer support for some cryptocurrencies on its network this year . the credit-card giant’s announcement comes days after Elon Musk’s Tesla Inc revealed it had purchased $1.5 billion of bitcoin . asset manager blackrock and payments companies Square and PayPal have also recently backed cryptocurrencies .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}