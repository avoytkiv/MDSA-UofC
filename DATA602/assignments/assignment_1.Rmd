---
title: "Assignment 1"
output:
    github_document:
        html_preview: false
        toc: true
        toc_depth: 2
---
## Problem 1
A recent study1 of college graduates in the United states discovered that approximately 60% of degree holders would “change their majors if they could go back to school” and re-do their undergraduate degree. Let’s presume this proportion also holds for Canadian undergraduate university degree holders.

One randomly selects two Canadians who hold an undergraduate degree. 
```{r}
p = 0.6
q = 1 - p
```

### A
both would change their undergraduate major (if they had the ability for a re-do).

**Answer**

Selecting randomly two Canadians are two _independent events_ - the occurrence of one event (pick up first Canadian) does not affect the occurrence of the other event (pick up second Canadian)
```{r}
p * p
```
### B
neither would change their undergraduate major (if they had the ability for a re-do).
```{r}
q * q
```
### C
at least one of the two would change their undergraduate major (if they had the ability for a re-do).

**Answer**

"at least one of the two would change..." means: 

1) first can change (p), second don't change (q) _or_ 

2) first don't change (q), second change (p)
```{r}
p * q + q * p
```
### D
Suppose you are to randomly pick n-Canadians with undergraduate degrees in such a way that the probability of at least one of them would change their undergraduate degree is 0.95. Compute the minimum number of Canadians with undergraduate degrees you would have to randomly select. In other words, compute the sample size n. (Hint: ln(ab)=b∗ln(a)…)

**Answer**:

1. "probability of at least one of them..." means the probability of one, two, three etc.

2. Complement event is _no one_ of them. P(at lest one of them) = 1 - P(no one of them). 

3. Probability (not changing degree) = q = 1 - p.  

4. 1 - q^n = 0.95 --> n = ln(0.05)/ln(q)

5. Round up to the next whole Canadian (to cross the threshold)

```{r}
ceiling(log(0.05)/log(q))
```

## Problem 2
### Step 1,2
```{r}
nsims = 1000  
outcome = numeric(nsims)
for(i in 1:nsims){ 
    outcome[i] = sample(c(1,2,3,4,5,6), 1, replace=FALSE) 
}  
simresult = data.frame(outcome) 
head(simresult,2) 
```
### Step 3
Below you will create histogram that displays the result of your 1000 simulated tosses of the fair die. After you create this data visuaulization, take particular notice of the distribution of the outcome of each number 1 through 6.

**Answer**:

Theoretically, the chance of each side of the dice is equal. But due to randomness, we observe that number of occurrences slightly differs. 
```{r}
library(ggplot2)
ggplot(data=simresult, aes(x = outcome)) + 
  geom_histogram(binwidth=1, col="red", fill='blue') + 
  ggtitle("Frequency Histogram of 1000 simulated Coin Tosses")
```
### Step 4
```{r}
nsims = 3000
outcome = numeric(nsims)
fivesix = numeric(nsims)

for(i in 1:nsims){ 
    outcome[i] = sample(c(1,2,3,4,5,6), 1, replace=FALSE)
    fivesix[i] = if (outcome[i] == 5 || outcome[i] == 6) 1 else 0
}  
simresult = data.frame(outcome) 
# head(simresult,2) 
```
### Question for Problem 2
Rather than a single trial result from the outcome of a simulated die toss, suppose a trial consisted of the three die tosses. An element in the sample space oi=(toss1,toss2,toss3). Moreover, on each trial you wish to observe if the sum of the three tosses is 14 or more. For example, a (5,6,3) outcome sums to 14 and satisifed the condition sum≥14. You wish to estimate the probability of observing a sum of 14 or more when three fair die are tossed. Run 3000 simulations.
```{r}
nsims = 3000
outcome = numeric(nsims)
sum14 = numeric(nsims)

for(i in 1:nsims){ 
    outcome[i] = list(sample(c(1,2,3,4,5,6), 3, replace=TRUE)) # sample three with replacement equivalent to three independent die tosses
}  
simresult = as.data.frame(t(data.frame(outcome))) # after transpose it's matrix, change to data.frame
rownames(simresult) = 1:nrow(simresult) # change index names of rows

simresult$total = rowSums(simresult[,c(1,2,3)]) # create sum of outcomes column
p_sum14 = dim(simresult[simresult$total >= 14, ])[1] / dim(simresult)[1] # calculate probability by dividing nrows that satisfy condition by total nrows
p_sum14
```
## Problem 3
### A
Compute the probability your hand will consist of a 10, Jack, Queen, King, and Ace of the same suit. 

**Answer**

1. Choose one suit out of four (), 

2. than choose five different values from possible five values (only one way to do this). 

3. Divide by all combinations of five cards out of twenty to find out probability
```{r}
choose(4, 1) * choose(5, 5) / choose(20, 5)
```

### B
Compute the probability that you get a three-of-a-kind.

**Answer**

1. Choose the value of the three of a kind (one value out of five possible), 

2. Choose three out of four for this value,

3. Choose the two cards that left to complete the "hand" out of 16 possible (20 cards - 4 for the first value)
```{r}
choose(5, 1) * choose(4, 3) * choose(16, 2) / choose(20, 5) 
```

### C
Compute probability that one observes two Aces and two ♢’s
**Answer**

To observe two diamonds and two aces there are two possible ways: 

1) an _ace is a diamond_ and a random card is a diamond:

- Choose Ace diamond - one way to do this

- Choose another random ace out of three that left

- Choose one more diamond out of four that left (5 diamond cards - 1 ace diamond)

- Choose two more cards out of 12 that left (20 cards - 4 aces (we don't want to observe any more aces ) - 5 diamonds + 1 ace diamond that is an intersection)

2) there is _no ace diamond among two aces_ (then there shold be two diamonds for random cards)

- Choose two aces out of three (exclude ace diamond in this configuration)

- Choose two diamond cards out of four diamonds (5 diamonds - 1 ace diamond)

- Choose one more card out of 12 that left to complete the hand
```{r}
ace_is_diamond = 1 * choose(3, 1) * choose(4, 1) * choose(12, 2)
ace_is_not_diamond = choose(3, 2) * choose(4, 2) * choose(12, 1)
p = (ace_is_diamond + ace_is_not_diamond) / choose(20, 5) 
p
```
## Problem 4

**Answer**

Used _conditional probability _
```{r}
p_AA = 0.15
p_UA = (1 - p_AA) / 4
p_D = 3 * p_UA
print(paste("Test: Total prob is", p_AA + p_UA + p_D))
p_AA_miss = 0.15
p_UA_miss = 0.3
p_D_miss = 0.1
p_UA_cond_miss = p_UA * p_UA_miss / (p_UA * p_UA_miss + p_AA * p_AA_miss + p_D * p_D_miss)
p_UA_cond_miss
```
## Problem 5
A random variable X has the following probability distribution function
```{r}
xvalues = c(0:15)
f = function(x){2/(3^{x+1})}
px = f(xvalues)
```

### A
Using R Studio, create a display that shows the probability distribution of this particular random variable X.For values of x, use xvalues = 0:15.
```{r}
plot(xvalues, px, type="h", col="blue")
```
### B
How likely is it to observe values beyond 3? Compute.

**Answer**

1. Beyond 3 means more than 3 - start with 4 (including)

2. 4th value is indexed 5th as values start from 0 and indexes from 1
```{r}
print(sum(px[5:16])) # more than 3, sum from 4 inclusive (indexed from 0)
```
### C
Compute the mean or expected value of X, E(X) or μX. (Hint: In computing E(X), change the upper limit on xvalues from 15 to 100…)
```{r}
xvalues = c(0:100)
px = f(xvalues)
ex = sum(xvalues * px) # expected value or mean is weighted sum
ex
```
### D
Compute the standard deviation of X, SD(X) or σX. (use the same values of x as you did in part (c))
```{r}
moment2 = sum(xvalues^{2}*px)
var = moment2 - ex^{2}
std = sqrt(var)
std
```
### E
Consider the interval (μX−σX,μX+σX). Compute P(μX−σX<X<μX+σX).
```{r}
lower = ex - std
upper = ex + std
print(lower)
print(upper)
```
```{r}
sum(px[1:2]) # find sum of 0 and 1 xvlaues
```

## Problem 6
### A
How likely is this outcome? Compute.

**Answer**:
The 35 successes out of 50 with this probability of our population 40% is _negligible_
```{r}
p = 0.4
n = 50
m = 35
x = c(0:n)
px = dbinom(x, n, p)
dbinom(35, n, p) # probability of 35 successes 
# plot(x, px, type="h", col="blue")
```
### B
From your computation in part (a), what do you think of the “40% statistic” quoted above is accurate? Ensure you use probability theory in your explanation.

**Answer**

1. Probability of seeing 35 "successes" and more is negligible

2. Num of successes from this sample should be somewhere around 20 - the expected value of distribution with 40% statistic

3. Our sample result is 30 standard deviations away from what was expected

4. _Conclusion_: statistic of 40% looks not adequate and should be higher
```{r}
p35 = 1 - pbinom(34, n, p) # prob of 35 and more
mean = n * p
std = sqrt(p*(1-p))
z = (m - mean) / std
print(p35)
print(mean)
print(std)
print(z)
```
### C
Suppose you are to randomly inspect n-Canadians aged 18 to 34 on this issue until you find the 10th to say “no sympathies” for people involved in the trucker conveys/protests. Compute the probability that n=30.

**Answer**

1. The process of choosing Canadians is a random experiment. 

2. Series of n-independent trials is the Binomial experiment. 

3. Out of 30 Canadians chosen, 10th should say no - success in our case. It means that out of 29 Canadians 9 already said no. 

4. Find probability of this series of independent events (event - pick up Canadiann randomly)

5. Find all combinations of this configuration: 29/9/20

6. And don't forget about 30th Canadian which is success with probability `p`
```{r}
choose(29, 9)*p^{9}*(1-p)^{29-9} * p
```
## Problem 7

It has taken 10 rounds to observe “odd person out”, or X=10. Did it take more trials than expected to observe “odd person out” or less? Ensure you incorporate course content in your explanation.

**Answer**

1. We have discrete distribution because values are integers - number of rounds

2. Create vector of as many values, so the probabilities sum up to 1 (dont restrict with 10)

3. Compute expectancy of this game to be able to compare this particular outcome (10 rounds to observe “odd person out”) with something that is _expected_ from this game.

4. Compute probability of seeing 10 rounds

5. _Conclusion_: 10 is much more than expected value 3.2. But what means "much more". Probability of to get observed outcome in 10 trials is approximately 1%.
```{r}
x = c(1:100)
f = function(x){0.3125*0.6875^{x-1}}
px = f(x)
print(sum(px))
ev = sum(x * px)

px[10]
ev
```

## Problem 8
In a certain beverage manufacturer’s factory, an automated soft-drink filling machine is to fill 2-litre bottles with product, the amount of soft-drink slightly varying from one 2-litre bottle to the next in according with a Normal probability model with a mean of μ=1.89 litres and a standard deviation of σ=0.05 litres.
```{r}
mean = 1.89
std = 0.05 
```
### A
You are to randomly pick a 2-litre bottle off the production line and measure its contents. Compute the probability that the amount of soft-drink dispensed into this bottle is between 1.83 and 1.91 litres.
```{r}
pnorm(1.91, mean, std) - pnorm(1.83, mean, std) 
```
### B
Find the 90th-percentile and interpret is meaning in the context of these data.

**Answer**

1. 90th quantile is 1.954078 litres

2. It means that probability that amount of soft-drink filled by automated machine is less than 1.95 litres. 90% of all bottles filled has less than 1.95 litres of soft-drink.   
```{r}
qnorm(0.90, mean, std)
```
### C
What proportion of all 2-litre bottles will be filled to overflow?
```{r}
1 - pnorm(2, mean, std)
```
### D
You are to randomly pick 50 2-litre bottles for inspection, measuring the amount of product dispensed into each of the bottles. Compute the probability that between 5 and 10 of these bottles will have less than 1.85 litres of soft-drink.

**Answer**
1. "randomly pick 50 2-litre bottles" - binomial experiment - series of Bernoulli trials. Randomly means independent events.

2. "will have less than 1.85 litres of soft-drink" - our random variable/event. Let it be `p`

3. How do we know `p`? From normal distribution calculate prob of "less than 1.85"
```{r}
p = pnorm(1.85, mean, std) # probability of bottle be less or equal than 1.85
print(p)
nsample = 50
x = c(1:nsample)
px = dbinom(x, nsample, p) # create binomial distribution 
sum(px[1:10]) - sum(px[1:4])
```
## Problem 9
### Load data
```{r}
gss = read.csv("http://people.ucalgary.ca/~jbstall/DataFiles/GSS2002.csv")
head(gss, 4)
```

```{r}
names(gss) 
```
```{r}
unique(gss$Race) 
```
### A Brief Tutorial on Bar Graphs
```{r}
ggplot(data=gss, aes(x = Religion, fill=Religion)) + 
  geom_bar(position="dodge", na.rm=TRUE) + 
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())

counts = as.data.frame(sort(table(gss$Religion)))
head(counts, 20)
ggplot(data=counts, aes(x=Var1, y=Freq, fill=Var1)) + 
  geom_bar(stat="identity") + 
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())

reliprop = counts$Freq/sum(counts$Freq) #converts counts to proportions
counts1 = data.frame(counts, reliprop) #create a new data frame adding reliprob variable to counts
# head(counts1, 4)

ggplot(data=counts1, aes(x=Var1, y=reliprop, fill=Var1)) + 
  geom_bar(stat="identity") + 
  ylab("Proportion") + 
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())
```

### A 
Create a bar graph that demonstrates the distribution of race within each level of education. What can you infer from this bar graph?
```{r}
sub_gss_A = na.omit(gss[,c("Education","Race")])

ggplot(data=sub_gss_A, aes(x = Education, fill=Race)) + 
  geom_bar(position = "dodge", na.rm=TRUE) 
```
From this visualization (straightforward approach) it is not clear. 
```{r}
sub_gss_A = na.omit(gss[,c("Education","Race")]) # select columns and remove NAs 
counts = table(sub_gss_A$Education, sub_gss_A$Race) 

rowTot = rowSums(counts) # sum in Education category
colTot = colSums(counts)

reliprop_col = t(t(counts)/colTot) # calc proportions
reliprop_row = counts/rowTot

ggplot(data.frame(reliprop_col), 
       aes(fill=factor(Var1, levels=c("Left HS","HS", "Jr Col", "Bachelors", "Graduate")), 
           y=Freq, 
           x=factor(Var2, 
                    levels = c("Black", "White", "Other")))) + 
    geom_bar(position="dodge", stat="identity") + 
    xlab("Race") + 
    ylab("Proportion")

ggplot(data.frame(reliprop_row), 
       aes(fill=Var2, 
           y=Freq, 
           x=factor(Var1, 
                    levels = c("Left HS","HS", "Jr Col", "Bachelors", "Graduate")))) + 
    geom_bar(position="dodge", stat="identity") + 
    xlab("Education") + 
    ylab("Proportion")
```
**Answer**

From this bar plot it is much more clear. 
1. Regarding the black race, _a quarter_ of them leave High School, and _slightly more than half_ manage to finish High School. After that, the _trend goes down_ for higher education, ending with less than 5% of graduate students.

2. For white people, almost _one-third_ of them get higher education (bachelor's + graduate). And the percentage of _dropping from school_ is the _lowest._

### B
Create a data visualization that can be used to demonstrate if there is a relationship between one’s marital status (Marital) and their education level.
```{r}
sub_gss_A = na.omit(gss[,c("Marital","Education")])
counts = table(sub_gss_A$Marital, sub_gss_A$Education)
rowTot <- rowSums(counts)
reliprop_row = counts/rowTot

ggplot(data.frame(reliprop_row), 
       aes(fill=Var2, 
           y=Freq, 
           x=Var1)) + 
    geom_bar(position="dodge", stat="identity") + 
    xlab("Marital status") + 
    ylab("Proportion")
```
**Answer**

1. Among those with marital status Widowed, they _rarely get higher education_ (bachelor + graduate). Approximately _half of them finish High School_. A _third of them leave high school_ - the highest proportion among other marital statuses.

2. Never Married or Married get their higher education _more often_ than Separated and Divorced.

### C
Create a data visualization that can be used to demonstrate if there is a relationship between one’s Gender and their Politics.
```{r}
sub_gss_A = na.omit(gss[,c("Gender","Politics")])
counts = table(sub_gss_A$Gender, sub_gss_A$Politics)

rowTot <- rowSums(counts)
colTot <- colSums(counts)

reliprop_col = t(t(counts)/colTot)
reliprop_row = counts/rowTot

ggplot(data.frame(reliprop_row), 
       aes(fill=Var2, 
           y=Freq, 
           x=Var1)) + 
    geom_bar(position="dodge", stat="identity") + 
    xlab("Gender") + 
    ylab("Proportion")

ggplot(data.frame(reliprop_col), 
       aes(fill=Var1, 
           y=Freq, 
           x=Var2)) + 
    geom_bar(position="dodge", stat="identity") + 
    xlab("Politics") + 
    ylab("Proportion") + coord_flip()
```
**Answer**

There are _no distinguishable differences_ between Males and Females respective to Political views, _except Extremely Conservative_, where the difference is the most significant (second plot - horizontal bars). Among the followers of Extremely Conservative views there are many more (40% more) Females than Males.

## Problem 10
```{r}
library(ISLR)
head(Default, 4)
```
### A
Create a scatterplot that demonstrates the relationship between a person’s income and their monthly balance they carry on their credit cards. Place the “income” variable as the y-axis and the “balance” variable as the x-axis. Within this visualization, differentiate between those who are students and those who are not.
```{r}
subset = na.omit(Default[,c("student", "balance", "income")])

ggplot(data=subset, 
       aes(x = income, y = balance, color=student)) + 
geom_point(size=2, position="jitter") + 
xlab("Monthly Balance") + 
ylab("Income") + 
facet_wrap(~ student) +  
ggtitle("Scatterplot of Monthly Balance and Income  - by status of being a student or not") + 
geom_smooth(method="lm")
```

### B
Create side-by-side boxplots that will compare the distributions of balance owing between students and non-students.
```{r}
ggplot(data=subset, aes(x = student, y=balance)) + 
geom_boxplot(fill='red', na.rm=TRUE) + 
ylab("Balance") + 
ggtitle("Boxplots of distributions of balance owing between students and non-students")  
```
### C
Compute the means, medians, standard deviations, x5, x95 (the 5th and 95th percentiles, respectively) for the data you visually summarized in part (b).

**Answer**

Student = "No"

mean = 771.7704

median = 759.1891

std = 469.6749 

x5 = 0.4246597

x95 = 1665.9625812 

---
Student = "Yes"

mean = 987.8182

median = 979.9894

std = 482.9097  

x5 = 0.4246597

x95 = 1665.9625812 
```{r}
library(mosaic)
favstats(~balance, data=filter(subset, student=="No"))
quantile(subset$balance, c(0.05, 0.95), na.rm = TRUE)
```
```{r}
favstats(~balance, data=filter(subset, student=="Yes"))
quantile(subset$balance, c(0.05, 0.95), na.rm = TRUE)
```
## Problem 11
### A
Read the data in this file into a data frame. Create a violin plot of these data.
```{r}
prob10 = read.csv("http://people.ucalgary.ca/~jbstall/DataFiles/Data602Assignment1Question11.csv")

ggplot(data = prob10, aes(x='var', y=Delivery_time)) + 
geom_violin(col="red", fill="blue") + 
xlab("") + 
ylab("") + 
ggtitle("")
```

### B
From this data, compute the sample mean, the sample median, the sample standard deviation, the first and third quartiles, and the 99th percentile.

**Answer**

mean = 5.6875

median = 5.775

std = 1.580369  

x1 = 3.0883

x99 = 7.9778 
```{r}
favstats(~Delivery_time, data=prob10)
quantile(prob10$Delivery_time, c(0.01, 0.99), na.rm = TRUE)
```

### C
Suppose you were part of a marketing campaign to promote the efficiency of delivery times, as a part of the campaign there was a promise of delivery within a certain number of hours, beyond which there would be a refund for 1% of all deliveries. Provide the point of refund.

**Answer**

1. " a refund for 1% of all deliveries" means the delivery was late - right tail of distribution

2. 1% of all deliveries are beyond _6 hours_ threshold 
```{r}
mean = 5
std = 1.5
sample_size = 12

std_sampple = std/sqrt(sample_size)
qnorm(0.99, mean, std_sampple)
```


