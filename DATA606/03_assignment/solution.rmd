---
title: "Assignment 3"
subtitle: Tree-based prediction models
author: |
    Andrii Voitkiv
date: "`r format(Sys.time(), '%a, %b %d, %Y')`"
geometry: margin=3cm
output:
    github_document:
        html_preview: false
        math_method: webtex
        toc: true
        toc_depth: 3
---

```{r global_options, echo = FALSE}
knitr::opts_chunk$set(fig.path='Figs/', fig.width=10, fig.height=12, fig.align='center', warning=FALSE, message=FALSE)
```

_**Name of the dataset**: “abalone”._
_**Package**: “AppliedPredictiveModeling”_

# Regrssion problem
_**Goal**: Predict the age of abalone from physical measurements. The age of abalone is determined by cutting the shell through the cone, staining it, and counting the number of rings through a microscope – a boring and time-consuming task. Other measurements, which are easier to obtain, are used to predict the age. Further information, such as weather patterns and location (hence food availability) may be required to solve the problem._

## Question 1
_Read the data from the package, check the names of the variables and the dimension of the dataset. (1pt)_
```{r}
# Load the package
library(AppliedPredictiveModeling)
# Read the data
data(abalone)
# Check the names of the variables
names(abalone)
# Check the dimension of the dataset
dim(abalone)
```

## Question 2
### 2.1 Split the dataset into two parts
_Split the dataset into two parts, where the training part contains 75% of the data and the test part contains the rest 25%_
```{r}
# Split the dataset into two parts using sample function
set.seed(10)
train_index <- sample(1:nrow(abalone), size = 0.75*nrow(abalone))
train <- abalone[train_index, ]
test <- abalone[-train_index, ]
```

### 2.2 Fit a regression tree to the data
_Fit a regression tree to the data with 'Rings' as the response variable and all the other variables as predictors_
```{r}
# Fit a regression tree to the data
library(tree)
tree_model <- tree(Rings ~ ., data = train)
summary(tree_model)
```

### 2.3 Plot the tree
_Plot the tree and show which variables are used to construct the tree._
```{r}
# Plot the tree
plot(tree_model)
text(tree_model, pretty = 0)
```

The variables used to construct the tree are `r summary(tree_model)$used`.

There are `r summary(tree_model)$size` terminal nodes in the tree.

### 2.4 Apply the tree to the test set
_Apply the tree to the test set, calculate the root square of the mean squared error (RMSE)._
```{r}
# Apply the tree to the test set
tree_pred <- predict(tree_model, test)
# Calculate the RMSE
RMSE <- sqrt(mean((tree_pred - test$Rings)^2))
RMSE
```
Compare (plot) the predicted responses and the observed responses in the test set
```{r fig.width=6, fig.height=4}
# Plot the predicted responses and the observed responses
plot(tree_pred, test$Rings)
abline(0, 1)
```

## Question 3
### 3.1 Select the “best” number of terminal nodes
_Check the plot between the cross-valiation error and the size of the tree, select the “best” number of terminal nodes (based on your own judgement). Prune the tree, plot the pruned tree and re-calculate the RMSE. (4pt)_
```{r fig.width=6, fig.height=4}
# Check the plot between the cross-valiation error and the size of the tree
cv.tree_model <- cv.tree(tree_model)
plot(cv.tree_model$size, cv.tree_model$dev, type = "b")
```

The best number of terminal nodes is 10, as it has the lowest cross-validation error.

### 3.2 Prune the tree
_Prune the tree, plot the pruned tree and re-calculate the RMSE._
```{r}
# Prune the tree
pruned_tree_model <- prune.tree(tree_model, best = 10)
# Plot the pruned tree
plot(pruned_tree_model)
text(pruned_tree_model, pretty = 0)
```

### 3.3 Apply the pruned tree to the test set
_Apply the tree to the test set, calculate the root square of the mean squared error (RMSE)._
```{r}
# Apply the tree to the test set
pruned_tree_pred <- predict(pruned_tree_model, test)
# Calculate the RMSE
RMSE_pruned <- sqrt(mean((pruned_tree_pred - test$Rings)^2))
```
RMSE of the pruned tree is `r RMSE_pruned` and the RMSE of the unpruned tree is `r RMSE`. The RMSE of the pruned tree is `r ifelse(RMSE_pruned < RMSE, "smaller", "greater")` than the RMSE of the unpruned tree, so the pruned tree is `r ifelse(RMSE_pruned < RMSE, "better", "worse")`.

## Question 4
### 4.1 Calculate the cross-validation error for linear regression
_Suppose you are interested in comparing the performance of linear regression and regression tree. Please use the following partitioned 10
folds to calculate the cross-validation error for these two methods (the cross-validation error is defined as the average of the RMSE)._
```{r}
# Create 10 folds
library(caret)
folds<-createFolds(abalone$Rings, k=10)
```
```{r}
# Calculate the cross-validation error for linear regression
library(MASS)
cv_error_lr <- c()
for (i in 1:10){
    train <- abalone[-folds[[i]], ]
    test <- abalone[folds[[i]], ]
    lr_model <- lm(Rings ~ ., data = train)
    lr_pred <- predict(lr_model, test)
    RMSE <- sqrt(mean((lr_pred - test$Rings)^2))
    cv_error_lr <- c(cv_error_lr, RMSE)
}
cv_error_lr <- mean(cv_error_lr)
```

### 4.2 Calculate the cross-validation error for regression tree
```{r}
# Calculate the cross-validation error for regression tree
cv_error_tree <- c()
for (i in 1:10){
    train <- abalone[-folds[[i]], ]
    test <- abalone[folds[[i]], ]
    tree_model <- tree(Rings ~ ., data = train)
    tree_pred <- predict(tree_model, test)
    RMSE <- sqrt(mean((tree_pred - test$Rings)^2))
    cv_error_tree <- c(cv_error_tree, RMSE)
}
cv_error_tree <- mean(cv_error_tree)
```

### 4.3 Compare the cross-validation error for linear regression and regression tree
Mean cross-validation error for linear regression is `r cv_error_lr` and mean cross-validation error for regression tree is `r cv_error_tree`. The cross-validation error for linear regression is _`r ifelse(cv_error_lr < cv_error_tree, "smaller", "greater")`_ than the cross-validation error for regression tree, so the linear regression is _`r ifelse(cv_error_lr < cv_error_tree, "better", "worse")`_.

# Classification problem
_Suppose now the variable of interest is Type. Please use what you learned from the classification tree to solve the questions._

## Question 5
### 5.1 Fit a classification tree to the data
_Under the same training and test parts as Q2 of regression problem, fit a classification tree to the training set using all the other variables as predictors._
```{r}
# Fit a classification tree to the data
library(tree)
tree_model <- tree(Type ~ ., data = train)
summary(tree_model)
```

### 5.2 Plot the tree
_Plot the fitted tree, which variables are used to construct the tree?_
```{r}
# Plot the tree
plot(tree_model)
text(tree_model, pretty = 0)
```

The variables used to construct the tree are `r summary(tree_model)$used`.

There are `r summary(tree_model)$size` terminal nodes in the tree.

The misclassification rate of the tree is `r summary(tree_model)$misclass[1] / summary(tree_model)$misclass[2]`.


### 5.3 Apply the tree to the test set
_Set the seed to 10, apply the fitted tree to the test set and calculate the misclassification rate._
```{r}
set.seed(10)
# Apply the tree to the test set
tree_pred <- predict(tree_model, test, type = "class")
# Calculate the misclassification rate
misclassification_rate <- mean(tree_pred != test$Type)
```
The misclassification rate is `r misclassification_rate`.

## Question 6
### 6.1 Prune the tree by checking the cross-validation errors
_Prune the tree by checking the cross-validation errors. Plot the pruned tree and re-calculate the misclassification rate. (4pt)_
```{r fig.width=6, fig.height=4}
# Prune the tree by checking the cross-validation errors
cv.tree_model <- cv.tree(tree_model, FUN = prune.misclass)
plot(cv.tree_model$size, cv.tree_model$dev, type = "b")
```

The best number of terminal nodes is 5, as it has the lowest cross-validation error.

```{r}
# build the pruned tree
pruned_tree_model <- prune.tree(tree_model, best = 3)
# Plot the pruned tree
plot(pruned_tree_model)
text(pruned_tree_model, pretty = 0)
```

### 6.2 Re-calculate the misclassification rate
```{r}
# Re-calculate the misclassification rate
pruned_tree_pred <- predict(pruned_tree_model, test, type = "class")
misclassification_rate_pruned <- mean(pruned_tree_pred != test$Type)
```
The misclassification rate of the pruned tree is `r misclassification_rate_pruned`.

## Question 7
_Suppose you are interested in comparing the performance between the linear discriminant analysis and the classification tree, please use the stratified 10
-fold cross-validation to calculate the cross-validation errors of these two methods (the cross-validation error here is defined as the average of the misclassification rate). Which method seems to work better? (6pt)_

### 7.1 Create 10 folds
```{r}
# Create 10 folds using 'datasets' package
library(datasets)
folds <- createFolds(abalone$Type, k = 10)
# Check the number of observations in each fold
fold1 <- abalone[folds[[1]], ]
table(fold1$Type)
```

### 7.2 Calculate the cross-validation error for LDA
```{r}
# Calculate the cross-validation error for LDA
library(MASS)
cv_error_lda <- c()
for (i in 1:10){
    train <- abalone[-folds[[i]], ]
    test <- abalone[folds[[i]], ]
    lda_model <- lda(Type ~ ., data = train)
    lda_pred <- predict(lda_model, test)
    misclassification_rate <- mean(lda_pred$class != test$Type)
    cv_error_lda <- c(cv_error_lda, misclassification_rate)
}
cv_error_lda <- mean(cv_error_lda)
```

### 7.3 Calculate the cross-validation error for classification tree
```{r}
# Calculate the cross-validation error for classification tree
cv_error_tree <- c()
for (i in 1:10){
    train <- abalone[-folds[[i]], ]
    test <- abalone[folds[[i]], ]
    tree_model <- tree(Type ~ ., data = train)
    tree_pred <- predict(tree_model, test)
    misclassification_rate <- mean(tree_pred != test$Type)
    cv_error_tree <- c(cv_error_tree, misclassification_rate)
}
cv_error_tree <- mean(cv_error_tree)
```

### 7.4 Compare the cross-validation error for LDA and classification tree
Mean cross-validation error for LDA is `r cv_error_lda` and mean cross-validation error for classification tree is `r cv_error_tree`. The cross-validation error for LDA is _`r ifelse(cv_error_lda < cv_error_tree, "smaller", "greater")`_ than the cross-validation error for classification tree, so the LDA is _`r ifelse(cv_error_lda < cv_error_tree, "better", "worse")`_.