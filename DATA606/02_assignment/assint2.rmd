---
title: 'Assignment 2'
author: 'Andrii Voitkiv'
date: "January 30, 2023"
output:
    github_document:
        math_method: webtex
        html_preview: false
        toc: true
        toc_depth: 2
---

```{r global_options}
knitr::opts_chunk$set(fig.path='Figs/')
```
## Question 1
Read the data “PimaIndiansDiabetes”, check the dimension of the dataset, the names of variables. Check how many classes there are (the variable “Diabetes”) and the class sizes. Check how R dummifies the “diabetes” variable. (3pt)
```{r}
# Read the data
library('mlbench')
data(PimaIndiansDiabetes)
# Check the dimension of the dataset
dim(PimaIndiansDiabetes)
# Check the names of variables
names(PimaIndiansDiabetes)
# Check how many classes there are (the variable “Diabetes”) and the class sizes
table(PimaIndiansDiabetes$diabetes)
```
The dataset has 768 observations and 9 variables.The names of variables are: preg, plas, pres, skin, test, mass, pedi, age, diabetes. There are two classes in the variable diabetes: neg and pos. The class sizes are 500 and 268, respectively.

## Question 2
Split the dataset into two parts – training and test.The training part contains 400 individuals from the “neg” class and 200 units from the “pos” class. The test part contains the rest data.
```{r}
# Sort the dataset by the variable “diabetes”
PimaIndiansDiabetes <- PimaIndiansDiabetes[order(PimaIndiansDiabetes$diabetes),]
# Select 400 individuals from the “neg” class and 200 units from the “pos” class
train_neg <- PimaIndiansDiabetes[1:400,]
train_pos <- PimaIndiansDiabetes[501:700,]
# Combine the two datasets
train <- rbind(train_neg, train_pos)
# Select the rest data as the test part
test <- PimaIndiansDiabetes[-c(1:400, 501:700),]
# Check the dimension of the training and test parts
dim(train)[1]
dim(test)[1]
```

Let “diabetes” be the response variable, get a logistic regression model based on the training part using all the explanatory variables, which variables contribute to the “pos” result in a negative way?
```{r}
# Get a logistic regression model based on the training part using all the explanatory variables
model <- glm(diabetes ~ ., data = train, family = binomial)
# Check the coefficients
summary(model)
```
```{r}
# Check encoding of the variable “diabetes”
contrasts(PimaIndiansDiabetes$diabetes)
```
Conclusion: Default encoding of the variable “diabetes” is 1 for "pos". There are no statistically _significant_ variables that contribute to the “pos” result in a negative way.


Check the “variance inflation factor” for each coefficient (e.g., using “vif” function from the package “car”). Do you detect multicollinearity?
```{r}
# Plot the correlation matrix with the help of the ggally package
library('GGally')
library('ggplot2')
ggpairs(PimaIndiansDiabetes, lower = list(continuous = "smooth_loess", combo = "facethist", discrete = "facetbar", na = "na"))

```

```{r}
# Check the “variance inflation factor” for each coefficient using imcdiag function from the package "regclass"
library('regclass')
VIF(model)
```
The correlation matrix shows that there is no multicollinearity between the variables. The variance inflation factor is less than 5 for all the variables, so there is no multicollinearity.

## Question 3
Apply your fitted logistic regression model to the test set. Suppose a prediction of “pos” is made if P(Y=pos|X1,…,Xp)≥0.5
, check the misclassification rate (the ratio between the number of incorrect predictions and test size). (4pt)
```{r}
# Apply the fitted logistic regression model to the test set
pred <- predict(model, test, type = "response")
# Check the misclassification rate
misclass_rate <- sum(ifelse(pred >= 0.5, 'pos', 'neg') != test$diabetes)/dim(test)[1]
# Print the misclassification rate
misclass_rate
```

## Question 4
Let the significance level be 0.1, remove the explanatory variables whose coefficients are NOT significantly different from 0. Re-fit a logistic regression model and repeat Step 3 to calculate the misclassification rate. (3pt)
```{r}
# Check the sificance level of the coefficients with the significance level 0.1
summary(model)
```
With the significance level 0.1, the coefficients of the variables pregnant, glucose, pressure, mass, pedigree are significantly different from 0. So, we will keep them in the model and will drop the rest.

```{r}
# Re-fit a logistic regression model
model2 <- glm(diabetes ~ pregnant + glucose + pressure + mass + pedigree, data = train, family = binomial)
# Check the coefficients
summary(model2)
```

```{r}
# Apply the fitted logistic regression model to the test set
pred2 <- predict(model2, test, type = "response")
# Check the misclassification rate
misclass_rate2 <- sum(ifelse(pred2 >= 0.5, 'pos', 'neg') != test$diabetes)/dim(test)[1]
# Print the misclassification rates
misclass_rate2
```
If we compare the misclassification rates of the two models, we can see that the misclassification rate of the second model is slightly lower than the misclassification rate of the first model. So, the second model is better than the first one.

## Question 5
Under the same training and test sets, apply a linear discriminant analysis (LDA) model to the training set using all the explanatory variables. Apply this fitted LDA model to the test set, calculate the misclassification rate based on the LDA-predicted results and the actual results. (3pt)